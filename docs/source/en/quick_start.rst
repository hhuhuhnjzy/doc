.. _quick_start:

Quick Start
===========

This guide walks you through running a complete Maze example: an **Automated Report Generation Workflow**. We'll use the code in ``test.py`` to demonstrate how to define tasks, build a dependency graph (DAG), submit a workflow, and retrieve the final result.

The workflow consists of the following four tasks:

1. **Create Initial Report**
2. **Add Analysis Section**
3. **Add Summary Section**
4. **Finalize and Generate Final Report**

Through this example, you‚Äôll experience Maze‚Äôs core features: **task-level scheduling**, **automatic dependency resolution**, and **parallel execution**.

Prerequisites
-------------

Ensure you have completed all steps in :ref:`installation`, including:

- Installed dependencies such as ``torch`` and ``ray``
- Run ``pip install -r requirements.txt`` and ``pip install -e .``
- (For Server Mode) Configured ``project_root`` in ``config/config.toml``

Step 1: Define Task Functions
-----------------------------

In Maze, each computational step is defined as an independent task using the ``@task`` decorator. Below are the four task functions used in this example:

.. code-block:: python
   :linenos:

   from maze.library.tasks.definitions import task
   import time

   @task(
       name="create_initial_report",
       description="Creates an initial report as the starting point of the workflow.",
       task_type='cpu',
       input_parameters={"properties": {"reporter_name": {"type": "string"}}},
       output_parameters={"properties": {"report_content": {"type": "string"}}}
   )
   def create_report(reporter_name: str) -> str:
       print(f"--- Task [create_initial_report] is running ---")
       report = f"Initial report generated by {reporter_name}."
       print(f"--- Task [create_initial_report] completed ---")
       return report

   @task(
       name="add_analysis_section",
       description="Adds an analysis section to the report.",
       task_type='cpu',
       input_parameters={"properties": {"base_report": {"type": "string"}}},
       output_parameters={"properties": {"updated_report": {"type": "string"}}}
   )
   def add_analysis(base_report: str) -> str:
       print(f"--- Task [add_analysis_section] is running ---")
       time.sleep(2)  # Simulate time-consuming data analysis
       updated_report = base_report + "\nSection: Data Analysis - Analysis complete."
       print(f"--- Task [add_analysis_section] completed ---")
       return updated_report

   @task(
       name="add_summary_section",
       description="Adds a summary section to the report.",
       task_type='cpu',
       input_parameters={"properties": {"base_report": {"type": "string"}}},
       output_parameters={"properties": {"updated_report": {"type": "string"}}}
   )
   def add_summary(base_report: str) -> str:
       print(f"--- Task [add_summary_section] is running ---")
       time.sleep(3)  # Simulate time-consuming summary generation
       updated_report = base_report + "\nSection: Summary - Summary complete."
       print(f"--- Task [add_summary_section] completed ---")
       return updated_report

   @task(
       name="finalize_report",
       description="Integrates all sections into the final report.",
       task_type='cpu',
       input_parameters={
           "properties": {
               "analysis_report": {"type": "string"},
               "summary_report": {"type": "string"}
           }
       },
       output_parameters={"properties": {"final_report": {"type": "string"}}}
   )
   def finalize_report(analysis_report: str, summary_report: str) -> str:
       print(f"--- Task [finalize_report] is running ---")
       final_report = f"--- FINAL REPORT ---\n{analysis_report}\n{summary_report.splitlines()[-1]}"
       print(f"--- Task [finalize_report] completed ---")
       return final_report

**Notes**:

- The ``@task`` decorator registers a task and allows you to specify its name, description, resource type (``task_type``), and input/output parameters.
- ``add_analysis`` and ``add_summary`` use ``time.sleep()`` to simulate time-consuming operations, highlighting the benefits of task-level scheduling.
- These two tasks can execute in parallel since they are independent of each other.

Step 2: Create a Client and Define the Workflow
-----------------------------------------------

Use ``MazeClient`` to connect to the Maze service and create a workflow object via ``new_workflow()``.

.. code-block:: python

   # Maze Client
   print("üöÄ [Step 1] Connecting to Maze Server...")
   SERVER_ADDRESS = "127.0.0.1:6380"
   client = MazeClient(server_address=SERVER_ADDRESS)
   print("‚úÖ [Step 1] Connection successful.\n")

   # Create workflow
   print("üöÄ [Step 2] Defining workflow blueprint...")
   report_workflow = client.new_workflow(name="Simple Report Generation Workflow")

Step 3: Add Tasks and Define Dependencies
-----------------------------------------

Use the ``add_task()`` method to add tasks to the workflow and declare dependencies using the ``{task_id}.output.{field}`` syntax.

.. code-block:: python

   # 1. Add the initial task
   task_a_id = report_workflow.add_task(
       create_report,
       task_name="Create Initial Report",
       inputs={'reporter_name': 'MazeBot'}
   )

   # 2. Add analysis task, dependent on the output of the initial task
   task_b_id = report_workflow.add_task(
       add_analysis,
       task_name="Add Analysis Section",
       inputs={'base_report': f'{task_a_id}.output.report_content'}
   )

   # 3. Add summary task, also dependent on the output of the initial task
   task_c_id = report_workflow.add_task(
       add_summary,
       task_name="Add Summary Section",
       inputs={'base_report': f'{task_a_id}.output.report_content'}
   )

   # 4. Add final task, dependent on outputs from both analysis and summary tasks
   final_task_id = report_workflow.add_task(
       finalize_report,
       task_name="Finalize The Report",
       inputs={
           'analysis_report': f'{task_b_id}.output.updated_report',
           'summary_report': f'{task_c_id}.output.updated_report'
       }
   )

   print("‚úÖ [Step 2] Workflow defined.\n")

**Notes**:

- ``task_a_id`` is the unique identifier for the first task.
- ``f'{task_a_id}.output.report_content'`` indicates that the input depends on the ``report_content`` output field of the ``create_report`` task.
- Since both ``add_analysis`` and ``add_summary`` depend only on ``create_report``, they will be **scheduled in parallel**, reducing total execution time.

Step 4: Visualize the Workflow Structure (Optional)
--------------------------------------------------

You can use the ``visualize()`` method to inspect the DAG structure, which is helpful for debugging and understanding:

.. code-block:: python

   # Visualize workflow
   compact_style = {
       'figsize': (8, 6),
       'title_fontsize': 20,
       'node_size': 5000,
       'node_fontsize': 8,
       'edge_fontsize': 14,
       'arrow_size': 100,
       'line_width': 2.0
   }
   report_workflow.visualize(style_options=compact_style)

This will generate a graphical DAG clearly showing task dependencies.

Step 5: Submit the Workflow and Retrieve Results
------------------------------------------------

Use the ``submit()`` method to send the workflow to the Maze cluster.

.. code-block:: python

   print("\nüöÄ [Step 3] Submitting workflow to server...")
   try:
       run_handle = report_workflow.submit(mode="local")  # Use local mode
       print(f"‚úÖ [Step 3] Workflow submitted. Run Handle: {run_handle}\n")
   except (ValueError, RuntimeError) as e:
       print(f"‚ùå [Step 3] Workflow validation or submission failed: {e}")

**Execution Mode Notes**:

- ``mode="local"``: Executes locally for development and debugging.
- ``mode="server"``: Submits to a distributed cluster for production execution.

Step 6: Wait for and Retrieve the Final Result
----------------------------------------------

Use ``get_task_result()`` to fetch the execution result of a task.

.. code-block:: python

   print("üöÄ [Step 4] Waiting for final task result...")
   result_info = run_handle.get_task_result(final_task_id, wait=True, timeout=300)

   print("\nüöÄ [Step 5] Processing final result...")
   if result_info.get("task_status") == "finished":
       final_report = result_info.get("data", {}).get("final_report", "No report content found.")
       print("\n--- ‚úÖ Final Report ---")
       print(final_report)
       print("----------------------\n")
   else:
       print(f"Task failed: {result_info.get('error')}")

**Expected Output**:

.. code-block:: text

   --- ‚úÖ Final Report ---
   --- FINAL REPORT ---
   Initial report generated by MazeBot.
   Section: Data Analysis - Analysis complete.
   Section: Summary - Summary complete.

Step 7: Display Execution Summary
---------------------------------

You can call ``display_summary()`` to view runtime statistics:

.. code-block:: python

   run_handle.display_summary()

Step 8: Clean Up Resources (Optional)
-------------------------------------

After submission, it‚Äôs recommended to clean up server-side resources:

.. code-block:: python

   print(f"\nüöÄ [Step 6] Cleaning up server resources...")
   if run_handle.destroy():
       print("‚úÖ [Step 6] Cleanup successful.")

‚úÖ Summary
----------

Through this example, you‚Äôve experienced Maze‚Äôs core capabilities:

- Defining schedulable tasks with ``@task``
- Building a DAG using ``add_task()`` and dependency syntax ``f"{task_id}.output.{field}"``
- Automatic parallel execution of independent tasks (``add_analysis`` and ``add_summary``)
- Submitting workflows and synchronously retrieving results

Next, try changing ``mode`` to ``"server"`` and run this workflow on a distributed cluster to experience Maze‚Äôs scalability.

You can create a file named ``quick_start_demo.py`` in your project root directory and combine the code snippets above to run the full demo.